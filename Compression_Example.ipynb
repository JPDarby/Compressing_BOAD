{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aims\n",
    "* demonstrate a simple implementation of the \\\\( W^TP_l\\\\) compression\n",
    "* show that this compression can be \"undone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quippy\n",
    "from quippy import descriptors\n",
    "\n",
    "\n",
    "import ase\n",
    "from ase.io import read, write\n",
    "import scipy\n",
    "import periodictable as PT\n",
    "import random\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions to setup SOAP params\n",
    "Note: These are not necessarily \"good\" parameters as this is just a toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_params(dataset):\n",
    "    \"\"\"Help function to construc a dictionary of SOAP params from a given dataset\"\"\"\n",
    "    species = set()\n",
    "    for s in dataset:\n",
    "        for atom in s:\n",
    "            species.add(atom.symbol)\n",
    "\n",
    "\n",
    "    params = {}\n",
    "    Zs = [PT.__dict__[el].number for el in species]\n",
    "\n",
    "    Zs = sorted(Zs, key = lambda x: x)\n",
    "    params[\"n_Z\"] = len(species)\n",
    "    params[\"n_species\"] = len(species)\n",
    "    Zstr = \"{\"\n",
    "    for Z in Zs:\n",
    "        Zstr += str(Z) + \" \"\n",
    "    all_Zs = Zs\n",
    "    Zstr = Zstr[:-1]+\"}\"\n",
    "    params[\"Z\"] = Zstr\n",
    "    params[\"species_Z\"] = Zstr\n",
    "    params[\"n_max\"] = 6\n",
    "    params[\"l_max\"] = 3\n",
    "    params[\"soap cutoff\"] = 5\n",
    "    params[\"atom_sigma\"] = 0.4\n",
    "    return params\n",
    "\n",
    "def params2quippy_str(params):\n",
    "    \"\"\"helper function to convert a dictionary of params to string format\"\"\"\n",
    "    qs = \"\"\n",
    "    for key, val in params.items():\n",
    "        qs += str(key) + \"=\" + str(val) + \" \"\n",
    "    return qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_ps(ps, params, random_key, norm=True):\n",
    "    \"\"\"compress the powerspectrum using W^T P_l\"\"\"\n",
    "    \n",
    "    N = round(params[\"n_max\"])\n",
    "    L = round(params[\"l_max\"])\n",
    "    S = round(params[\"n_Z\"])\n",
    "    \n",
    "    \n",
    "    #1. split up into NxN matrices each with fixed l\n",
    "    l_slices = split_ps2(ps, N*S, L)\n",
    "    \n",
    "    #2. compress each matrix using the random_key\n",
    "    short = []\n",
    "    for l in range(0, L+1):\n",
    "        Pl = l_slices[l]\n",
    "        W = random_key[:,:2*l+1]\n",
    "        short += list(np.dot(W.T, Pl).flatten())\n",
    "    short = np.array(short)\n",
    "    if norm:\n",
    "        short = short/np.linalg.norm(short)\n",
    "    return short\n",
    "    \n",
    "def ps2slices(ps, NS, L):\n",
    "    \"\"\"Splits the power spectrum into an (L+1, NS, NS) numpy array of l-slices\"\"\"\n",
    "    \n",
    "    #1. reshape the power spectrum\n",
    "    l_slices = np.zeros((L+1, NS, NS))\n",
    "    i = 0\n",
    "    c = 2**-0.5\n",
    "    for n1 in range(0, NS):\n",
    "        for n2 in range(0, n1+1):\n",
    "            for l in range(0, L+1):\n",
    "                p = ps[(L+1)*i+l]\n",
    "                if n1 == n2:\n",
    "                    l_slices[l][n1][n2] = p\n",
    "                else:\n",
    "                    p = p * c\n",
    "                    l_slices[l][n1][n2] = p\n",
    "                    l_slices[l][n2][n1] = p\n",
    "            i += 1 \n",
    "    return l_slices\n",
    "\n",
    "def gen_random_key(params):\n",
    "    \"\"\"Generate a 'random key' to use in compression\"\"\"\n",
    "    N = round(params[\"n_max\"])\n",
    "    L = round(params[\"l_max\"])\n",
    "    S = round(params[\"n_Z\"])\n",
    "    ncols = min([N*S, 2*L+1])\n",
    "    nrows = N*S\n",
    "    return 0.1 + 0.8 *np.random.sample(size=(nrows, ncols))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to undo Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncompress_slice(WtP, l, RK):\n",
    "    \"\"\"take in a compressed slice and the random key and uncompress\"\"\"\n",
    "\n",
    "    def get_IR(A):\n",
    "        \"\"\"find and return linearly independent rows of A\n",
    "        also return indicies of those rows\"\"\"\n",
    "        T = []\n",
    "        inds = []\n",
    "        cur_rank = 0\n",
    "        for i, row in enumerate(A):\n",
    "            T.append(row)\n",
    "            rank = np.linalg.matrix_rank(T)\n",
    "            if rank > cur_rank:\n",
    "                cur_rank = rank\n",
    "                inds.append(i)\n",
    "            else:\n",
    "                T = T[:-1]\n",
    "\n",
    "        #Think this check goes awry sometimes due to numerical issues\n",
    "        #if this is happening then don't need the missing rows\n",
    "        #assert np.linalg.matrix_rank(T) == np.linalg.matrix_rank(A)\n",
    "        return T, inds\n",
    "\n",
    "\n",
    "    W = RK[:, :2*l+1]\n",
    "    #get r equations, where r = rank(Pl) == rank(WtP) <= 2*l+1\n",
    "    T, inds = get_IR(WtP)\n",
    "    \n",
    "    #sometimes WtP can be exactly zero by symmetry -> return zeros\n",
    "    if len(inds) == 0:\n",
    "        assert np.linalg.matrix_rank(WtP) == 0\n",
    "        NS = W.shape[0]\n",
    "        return np.zeros((NS,NS))\n",
    "\n",
    "    \n",
    "    #reduced rows\n",
    "    C = np.dot(WtP, W)\n",
    "    C = C[inds,:][:,inds]\n",
    "    \n",
    "    #find eigenvalues and check the reconsruction\n",
    "    vals, Ut = np.linalg.eigh(C)\n",
    "    U = Ut.T\n",
    "    Lambda = np.diag(vals)\n",
    "    R = np.dot(U.T, np.dot(Lambda, U))\n",
    "    assert np.allclose(R, C)\n",
    "    \n",
    "    #Solve for original Pl\n",
    "    roots = [x**-0.5 for x in vals]\n",
    "    #Truncate to avoid numerical issues, using relative size of 1e-10 for truncation\n",
    "    min_pos = min([x for x in roots if x > 0])\n",
    "    #Gram matricies should be positive semi-definite\n",
    "    roots = [x if x > 0 else min_pos*1e-15 for x in roots]\n",
    "    D = np.diag(roots)\n",
    "    X = np.dot(D, np.dot(U, T))\n",
    "    P = np.dot(X.T, X)\n",
    "    assert np.allclose(np.dot(W.T, P), WtP)\n",
    "  \n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the Li-TM dataset\n",
    "Artrith, Nongnuch, Alexander Urban, and Gerbrand Ceder. \"Efficient and accurate machine-learning interpolation of atomic energies in compositions with many species.\" Physical Review B 96.1 (2017): 014112.\n",
    "https://journals.aps.org/prb/abstract/10.1103/PhysRevB.96.014112\n",
    "\n",
    "* Download will fail if you do not have access rights to this journal.\n",
    "* Connecting to your institutions VPN can help\n",
    "* If this fails replace Li-TM dataset with a different one. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making dataests folder\n",
      "downloading Li-TM dataset\n",
      "unzipping\n",
      "CPU times: user 3.56 s, sys: 4.58 s, total: 8.14 s\n",
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not os.path.exists(\"datasets\"):\n",
    "    print(\"making dataests folder\")\n",
    "    os.mkdir(\"datasets\")\n",
    "if not os.path.exists(\"datasets/Li-TM.zip\"):\n",
    "    print(\"downloading Li-TM dataset\")\n",
    "    url = \"https://journals.aps.org/prb/supplemental/10.1103/PhysRevB.96.014112/LiMO2-reference-data-11-species.zip\"\n",
    "    urllib.request.urlretrieve(url, \"datasets/Li-TM.zip\")\n",
    "\n",
    "if not os.path.exists(\"datasets/LiMO2-reference-data-11-species/xsf-files/structure10415.xsf\"):\n",
    "    print(\"unzipping\")\n",
    "    with zipfile.ZipFile(\"datasets/Li-TM.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"datasets/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsf_files = glob.glob(\"datasets/LiMO2-reference-data-11-species/xsf-files/*.xsf\")\n",
    "random.shuffle(xsf_files)\n",
    "dataset = [read(f) for f in xsf_files[:1000]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress the power spectrum then undo the compression\n",
    "* convert the power spectrum to (L+1, NS, NS) array of \"l-slices\", and leave in this form for convienience\n",
    "* check reconstruction for 1000 random structures\n",
    "* It is possible for the reconstruction to fail if \\\\( \\text{rank}(W^TP_l) < \\text{rank}(P_l) \\\\) due to an unfortunate choice of \\\\( W\\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 999 Success"
     ]
    }
   ],
   "source": [
    "params = dataset_to_params(dataset)\n",
    "qs = params2quippy_str(params)\n",
    "N = round(params[\"n_max\"])\n",
    "L = round(params[\"l_max\"])\n",
    "S = round(params[\"n_Z\"])\n",
    "RK = gen_random_key(params)\n",
    "\n",
    "for i, struc in enumerate(dataset):\n",
    "    #compute regular power spectrum\n",
    "    desc = descriptors.Descriptor(qs)\n",
    "    output = desc.calc(struc)\n",
    "    ps = output[\"data\"][0][:-1]\n",
    "    assert len(ps) == round(0.5*N*S*(N*S+1)*(L+1))\n",
    "    full_slices = ps2slices(ps, N*S, L)\n",
    "    ps2 = full_slices.flatten()\n",
    "    assert abs(np.linalg.norm(ps2)-1) < 1e-6\n",
    "\n",
    "    #Compress\n",
    "    comp_slices = [np.dot(RK[:,:2*l+1].T, Pl) for l, Pl in enumerate(full_slices)]\n",
    "    n_short = sum([len(x.flatten()) for x in comp_slices])\n",
    "    assert n_short == N*S*(L+1)**2\n",
    "\n",
    "    #undo compression, using only compressed power spectrum and 'random key'\n",
    "    recon_slices = np.array([uncompress_slice(WtP, l, RK) for l, WtP in enumerate(comp_slices)])\n",
    "\n",
    "    #check the reconstruction\n",
    "    if np.allclose(full_slices, recon_slices):\n",
    "        print(\"\\r\", i, \"Success\",  end=\"\")\n",
    "    else:\n",
    "        print(\"RECONSTRUCTION FAILED!!\")\n",
    "        raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
